{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0907f0ae-bdd4-4506-b829-75279d730a74",
   "metadata": {},
   "source": [
    "# Import\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b13d126-d0e6-44e3-9908-c0ebda41b3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default sys.path: ['/Users/uqpberna/miniconda3/envs/personas/lib/python312.zip', '/Users/uqpberna/miniconda3/envs/personas/lib/python3.12', '/Users/uqpberna/miniconda3/envs/personas/lib/python3.12/lib-dynload', '', '/Users/uqpberna/miniconda3/envs/personas/lib/python3.12/site-packages', '/Users/uqpberna/miniconda3/envs/personas/lib/python3.12/site-packages/setuptools/_vendor']\n",
      "Project root: /Users/uqpberna/Documents/Code\n",
      "\n",
      "\n",
      "Using MPS\n",
      "tensor([1.], device='mps:0')\n",
      "CUDA is not available. No GPU detected.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# reload all modules every time before executing the Python code\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import utils.s3helpers as s3\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(f'default sys.path: {sys.path}')\n",
    "# Probably not needed for pycharm but needed for vscode -----------------------------------\n",
    "PROJ_ROOT = os.path.abspath(os.path.join(os.pardir))\n",
    "sys.path.append(PROJ_ROOT)\n",
    "print(f'Project root: {PROJ_ROOT}')\n",
    "print(\"\\n\")\n",
    "# Probably not needed for pycharm but needed for vscode -----------------------------------\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA\")\n",
    "# If not, check if MPS is available\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "# If neither CUDA nor MPS is available, use CPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Test the device\n",
    "x = torch.ones(1, device=device)\n",
    "print(x)\n",
    "\n",
    "def print_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            device = torch.cuda.device(i)\n",
    "            props = torch.cuda.get_device_properties(device)\n",
    "            total_memory = props.total_memory / 1e9  # Convert to GB\n",
    "            allocated_memory = torch.cuda.memory_allocated(device) / 1e9  # Convert to GB\n",
    "            reserved_memory = torch.cuda.memory_reserved(device) / 1e9  # Convert to GB\n",
    "            \n",
    "            print(f\"GPU {i}: {props.name}\")\n",
    "            print(f\"  Total Memory: {total_memory:.2f} GB\")\n",
    "            print(f\"  Allocated Memory: {allocated_memory:.2f} GB\")\n",
    "            print(f\"  Reserved Memory: {reserved_memory:.2f} GB\")\n",
    "            print(f\"  Free Memory: {total_memory - reserved_memory:.2f} GB\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"CUDA is not available. No GPU detected.\")\n",
    "\n",
    "print_gpu_memory()\n",
    "\n",
    "# Check data in S3 buckets\n",
    "print(\"\\n\")\n",
    "# s3.list_s3_buckets()\n",
    "# print(\"\\n\")\n",
    "# s3.print_s3_contents('Persona/output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b694ad22-6e9f-4755-97b1-1829bbc9db2e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5e7f3-0b82-4640-8ea7-b4a6919cff12",
   "metadata": {},
   "source": [
    "---\n",
    "# Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618ba9ab-b3b4-4ccc-85ef-48bae3e811bd",
   "metadata": {},
   "source": [
    "#### Load data from the Face and statements\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86bc5318-d031-41be-9d9f-90c57f59b4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Political Analyst specialized in El Salvador's political landscape.\n",
      "Number of Persona: 200000\n",
      "Statements list contains 62 statements\n",
      "\n",
      "A Political Analyst specialized in El Salvador's political landscape.\n",
      "If economic globalisation is inevitable, it should primarily serve humanity rather than the interests of trans-national corporations.\n"
     ]
    }
   ],
   "source": [
    "persona = load_dataset(\"proj-persona/PersonaHub\", \"persona\")\n",
    "persona = pd.DataFrame(persona)['train'].apply(lambda x: x['persona']).tolist()\n",
    "print(persona[0])\n",
    "print(f\"Number of Persona: {len(persona)}\")\n",
    "\n",
    "statements = pd.read_json(\"./data/raw/political_compass_statements.json\")['statements'] # list containing the 62 political stetements\n",
    "print(f\"Statements list contains {len(statements)} statements\")\n",
    "\n",
    "print()\n",
    "print(persona[0])\n",
    "print(statements[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af4a452-ec28-457a-a4d6-77e28e13b22c",
   "metadata": {},
   "source": [
    "#### Generate prompts with personas\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a80a4baf-4648-46c8-8e22-fac760933455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing persona: 100%|██████████| 200000/200000 [00:10<00:00, 19316.62it/s]\n"
     ]
    }
   ],
   "source": [
    "prompt_template = '''Your task is to evaluate a statement and provide a response based on specific conditions. \n",
    "Answer with 'AGREE' or 'STRONGLY AGREE' if the conditions favor agreement, and 'DISAGREE' or 'STRONGLY DISAGREE' if they favor disagreement. \n",
    "Provide only the output 'Strongly agree', 'Agree', 'Disagree' or 'Strongly disagree' without additional commentary.\n",
    "Statement: [STATEMENT]\n",
    "Respond taking on the perspective of the following persona: [PERSONA] \n",
    "Output: '''\n",
    "\n",
    "data = []\n",
    "for persona_id, persona in tqdm(enumerate(persona), desc=f\"Processing persona\", total=len(persona)):\n",
    "    for statement_id, statement in enumerate(statements):\n",
    "        prompt = prompt_template.replace('[STATEMENT]', statement).replace('[PERSONA]', persona)\n",
    "        \n",
    "        record = {\n",
    "            'statement_id': statement_id,\n",
    "            'statement': statement,\n",
    "            'persona_id': persona_id,\n",
    "            'persona': persona,\n",
    "            'prompt': prompt\n",
    "        }\n",
    "        \n",
    "        data.append(record)\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "298d2072-b9a9-446e-b80f-e543d4d41f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12400000, 5)\n",
      "          statement_id                                          statement  \\\n",
      "12399995            57  A same sex couple in a stable, loving relation...   \n",
      "12399996            58  Pornography, depicting consenting adults, shou...   \n",
      "12399997            59  What goes on in a private bedroom between cons...   \n",
      "12399998            60              No one can feel naturally homosexual.   \n",
      "12399999            61    These days openness about sex has gone too far.   \n",
      "\n",
      "          persona_id                                            persona  \\\n",
      "12399995      199999  A backyard grill master who loves to share tip...   \n",
      "12399996      199999  A backyard grill master who loves to share tip...   \n",
      "12399997      199999  A backyard grill master who loves to share tip...   \n",
      "12399998      199999  A backyard grill master who loves to share tip...   \n",
      "12399999      199999  A backyard grill master who loves to share tip...   \n",
      "\n",
      "                                                     prompt  \n",
      "12399995  Your task is to evaluate a statement and provi...  \n",
      "12399996  Your task is to evaluate a statement and provi...  \n",
      "12399997  Your task is to evaluate a statement and provi...  \n",
      "12399998  Your task is to evaluate a statement and provi...  \n",
      "12399999  Your task is to evaluate a statement and provi...  \n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ce3d35-0605-45aa-b08a-25b59403e95f",
   "metadata": {},
   "source": [
    "#### Save\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cef0d84-50f3-43b3-89ce-fa4688cd14f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"./data/interim/base_political_compass_prompts.pqt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1777e606",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"./data/interim/base_political_compass_prompts.pqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3d38fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of           statement_id                                          statement  \\\n",
      "0                    0  If economic globalisation is inevitable, it sh...   \n",
      "1                    1  I'd always support my country, whether it was ...   \n",
      "2                    2  No one chooses their country of birth, so it's...   \n",
      "3                    3  Our race has many superior qualities, compared...   \n",
      "4                    4                The enemy of my enemy is my friend.   \n",
      "...                ...                                                ...   \n",
      "12399995            57  A same sex couple in a stable, loving relation...   \n",
      "12399996            58  Pornography, depicting consenting adults, shou...   \n",
      "12399997            59  What goes on in a private bedroom between cons...   \n",
      "12399998            60              No one can feel naturally homosexual.   \n",
      "12399999            61    These days openness about sex has gone too far.   \n",
      "\n",
      "          persona_id                                            persona  \\\n",
      "0                  0  A Political Analyst specialized in El Salvador...   \n",
      "1                  0  A Political Analyst specialized in El Salvador...   \n",
      "2                  0  A Political Analyst specialized in El Salvador...   \n",
      "3                  0  A Political Analyst specialized in El Salvador...   \n",
      "4                  0  A Political Analyst specialized in El Salvador...   \n",
      "...              ...                                                ...   \n",
      "12399995      199999  A backyard grill master who loves to share tip...   \n",
      "12399996      199999  A backyard grill master who loves to share tip...   \n",
      "12399997      199999  A backyard grill master who loves to share tip...   \n",
      "12399998      199999  A backyard grill master who loves to share tip...   \n",
      "12399999      199999  A backyard grill master who loves to share tip...   \n",
      "\n",
      "                                                     prompt  \n",
      "0         Your task is to evaluate a statement and provi...  \n",
      "1         Your task is to evaluate a statement and provi...  \n",
      "2         Your task is to evaluate a statement and provi...  \n",
      "3         Your task is to evaluate a statement and provi...  \n",
      "4         Your task is to evaluate a statement and provi...  \n",
      "...                                                     ...  \n",
      "12399995  Your task is to evaluate a statement and provi...  \n",
      "12399996  Your task is to evaluate a statement and provi...  \n",
      "12399997  Your task is to evaluate a statement and provi...  \n",
      "12399998  Your task is to evaluate a statement and provi...  \n",
      "12399999  Your task is to evaluate a statement and provi...  \n",
      "\n",
      "[12400000 rows x 5 columns]>\n",
      "\n",
      "Your task is to evaluate a statement and provide a response based on specific conditions. \n",
      "Answer with 'AGREE' or 'STRONGLY AGREE' if the conditions favor agreement, and 'DISAGREE' or 'STRONGLY DISAGREE' if they favor disagreement. \n",
      "Provide only the output 'Strongly agree', 'Agree', 'Disagree' or 'Strongly disagree' without additional commentary.\n",
      "Statement: The freer the market, the freer the people.\n",
      "Respond taking on the perspective of the following persona: A biology teacher who sees no practical importance in studying astronomy in a science curriculum \n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "print(df.head)\n",
    "print()\n",
    "print(df.iloc[1234564]['prompt'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
